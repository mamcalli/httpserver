#!/bin/bash

# Constants
SERVER_EXEC="./httpserver"    # Path to the HTTP server executable
TEST_PORT=8080                # Port on which the HTTP server will run
TEST_DIR="test_files"         # Directory containing the test files to upload/download
TMP_DIR="tmp_test"            # Temporary directory for storing downloaded files during testing
LOG_FILE="audit.log"          # Audit log file generated by the server
SERVER_LOG="server_output.log" # File to capture server runtime logs
CURL_LOG="curl_output.log"    # File to capture curl output for debugging

# Ensure the test environment is clean before starting
cleanup() {
    echo "Cleaning up..."
    # Kill any running instance of the HTTP server
    killall httpserver &>/dev/null
    # Remove temporary files, server logs, and curl logs
    rm -rf "$TMP_DIR"
    rm -f "$SERVER_LOG" "$LOG_FILE" "$CURL_LOG"
}
# Register cleanup function to execute upon script exit, ensuring proper cleanup
trap cleanup EXIT

# Prepare temporary directory for testing
mkdir -p "$TMP_DIR"

# Start the HTTP server
echo "Starting HTTP server..."
# Launch the server with 4 threads and bind it to the specified port
$SERVER_EXEC -t 4 $TEST_PORT &>$SERVER_LOG &
SERVER_PID=$!  # Capture the server's process ID for later termination
sleep 2        # Allow the server some time to start

# Check if the server started successfully
if ! ps -p $SERVER_PID > /dev/null; then
    echo "Failed to start server."
    exit 1
fi
echo "HTTP server started with PID: $SERVER_PID"

# Helper function for running individual test cases
test_case() {
    local description="$1"      # Description of the test case
    local command="$2"          # Command to execute the test
    local expected_code="$3"    # Expected return code of the command

    echo -n "Testing: $description... "
    # Run the test command and capture its output in the curl log
    eval "$command" > "$CURL_LOG" 2>&1
    local actual_code=$?  # Capture the actual return code of the command

    # Compare the actual return code with the expected code
    if [ "$actual_code" -eq "$expected_code" ]; then
        echo "PASSED"  # Test passed
    else
        echo "FAILED (Expected $expected_code, Got $actual_code)"  # Test failed
        echo "Command: $command"
        echo "Output:"
        cat "$CURL_LOG"  # Display the curl log for debugging
    fi
}

# Test cases begin here
echo "Running tests..."

# Test PUT requests: Upload all test files to the server
for file in "$TEST_DIR"/*.txt; do
    filename=$(basename "$file")  # Extract the filename from the file path
    test_case "PUT $filename" \
        "curl -X PUT --data-binary @$file http://localhost:$TEST_PORT/$filename" 0
done

# Test GET requests: Retrieve each uploaded file and verify its content
for file in "$TEST_DIR"/*.txt; do
    filename=$(basename "$file")  # Extract the filename from the file path
    test_case "GET $filename" \
        "curl -X GET http://localhost:$TEST_PORT/$filename -o $TMP_DIR/$filename" 0
    # Verify the retrieved file matches the original
    if diff "$file" "$TMP_DIR/$filename" > /dev/null; then
        echo "Content verified for $filename"  # Content matches
    else
        echo "Content mismatch for $filename"  # Content does not match
    fi
done

# Check if the audit log is generated and display its contents
echo "Checking audit log..."
if [ -f "$LOG_FILE" ]; then
    echo "Audit log generated:"
    cat "$LOG_FILE"  # Display the contents of the audit log
else
    echo "Audit log not found!"  # Audit log is missing
fi

# Test unsupported HTTP methods: DELETE method
test_case "Unsupported DELETE method" \
    "curl -X DELETE http://localhost:$TEST_PORT/antihero.txt" 1

# Test error handling for non-existent resources
test_case "GET non-existent file" \
    "curl -X GET http://localhost:$TEST_PORT/nonexistent.txt" 1

# Test handling of large file uploads
# Generate a random 10 MB file for testing
dd if=/dev/urandom of="$TMP_DIR/largefile.txt" bs=1M count=10
test_case "PUT large file" \
    "curl -X PUT --data-binary @$TMP_DIR/largefile.txt http://localhost:$TEST_PORT/largefile.txt" 0

# Concurrency test: Simulate multiple simultaneous GET requests
echo "Running concurrency test..."
for i in {1..20}; do
    curl -X GET http://localhost:$TEST_PORT/antihero.txt &
done
wait  # Wait for all background processes to complete
echo "Concurrency test completed."

# Stress test: Measure server performance under heavy load
echo "Running stress test..."
if command -v ab > /dev/null; then
    # Use ApacheBench (ab) to send 1000 requests with 50 concurrent connections
    ab -n 1000 -c 50 http://localhost:$TEST_PORT/antihero.txt
else
    echo "ApacheBench not installed. Skipping stress test."
fi

# Gracefully shut down the server
echo "Stopping HTTP server..."
kill -SIGTERM $SERVER_PID  # Send SIGTERM to the server process
wait $SERVER_PID  # Wait for the server process to terminate

echo "All tests completed."
